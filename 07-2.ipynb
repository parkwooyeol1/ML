{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2b297f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 케라스  API를 사용 패션MNIST 데이터셋 불러오기\n",
    "import keras\n",
    "(train_input, train_target), (test_input, test_target) =\\\n",
    "    keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# 픽셀값 변환 및 1차원 배열로 바꾸기, 사이킷런으로 훈련세트와 검증세트로 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_scaled = train_input/255.0\n",
    "train_scaled = train_scaled.reshape(-1,28*28)\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3188e013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력층과 출력층 사이에 밀집층 추가\n",
    "# 입력층과 출력층 사이에 있는 모든 층을 은닉층이라고 한다.\n",
    "# 은닉층의 활성화 함수는 비교적 자유롭다(출력층은 시그모이드함수, 소프트맥스함수)\n",
    "# 은닉층에 활성화 함수가 필요한이유? -> 선형만 계산하면 아무리 층을 쌓아도 결국 하나의 선형모델이 돼버린다 ->  복잡한 문제를 풀지 못함\n",
    "# 따라서 선형계산을 비선형적으로 만들어주기 위해서\n",
    "\n",
    "# 시그모이드 활성화 함수를 사용한 은닉층과 소프트 맥스 함수를 사용한 출력층을 케라스의 Dense 클래스로 만들기\n",
    "inputs = keras.layers.Input(shape=(784,))\n",
    "dense1 = keras.layers.Dense(100, activation='sigmoid') #100개의 뉴런\n",
    "dense2 = keras.layers.Dense(10, activation='softmax') #10개의 뉴런"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c48ab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 심층 신경망 만들기\n",
    "model = keras.Sequential([inputs, dense1, dense2]) # 입력층을 맨앞에, 출력층을 맨뒤에"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8f79b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79510 (310.59 KB)\n",
      "Trainable params: 79510 (310.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# summary() 메서드를 호출하면 층에 대한 정보확인 가능\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9733e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 번째 차원은 샘플 개수를 나타내지만, 미니배치경사하강법을 이용하여 나누어 데이터를 사용하기 때문에 None으로 정의 -> 배치차원\n",
    "# None-trainable params -> 경사하강법으로 훈련되지 않은 파라미터 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b704e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"패션 MNIST 모델\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden_layer (Dense)        (None, 100)               78500     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79510 (310.59 KB)\n",
      "Trainable params: 79510 (310.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 층을 추가하는 다른 방법\n",
    "model = keras.Sequential([\n",
    "   keras.layers.Input(shape=(784,)),\n",
    "   keras.layers.Dense(100, activation='sigmoid', name='hidden_layer'),\n",
    "   keras.layers.Dense(10, activation='softmax', name='output_layer')\n",
    "   ], name='패션 MNIST 모델') \n",
    "\n",
    "model.summary()\n",
    "# Seqeuential 클래스 생성자가 매우 길어짐, 조건에 따라 층을 추가 할 수 없을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "410577da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79510 (310.59 KB)\n",
      "Trainable params: 79510 (310.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# add() 메서드를 호출하여 층을 추가하는 방법\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Input(shape=(784,)))\n",
    "model.add(keras.layers.Dense(100, activation='sigmoid'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddb8bf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5714 - accuracy: 0.8033\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4130 - accuracy: 0.8509\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3778 - accuracy: 0.8638\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3546 - accuracy: 0.8711\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3379 - accuracy: 0.8784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7a3548379ff0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5번의 에포크 동안 훈련\n",
    "model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_scaled, train_target, epochs=5)\n",
    "# 인공신경망에 몇 개의 층을 추가하더라도 compile() 메서드와 fit() 메서드의 사용법은 동일 -> 케라스API의 장점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3be5ea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시그모이드 함수는 층이 많을 수록 (그래프가 누워있어) 그 효과가 누적되어 학습을 어렵게 함\n",
    "# 렐루함수 -> z가 0보다 크면 z를 출력, 0보다 작으면 0을 출력\n",
    "# 렐루 함수는 특히 이미지 처리에서 좋은 성능을 냄 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50187215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79510 (310.59 KB)\n",
      "Trainable params: 79510 (310.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Flatten 클래스는 배치 차원을 제외하고 나머지 입력 차원을 모두 일렬로 펼치는 역할만 한다.\n",
    "# ex. (32, 28, 28) ->(32, 784), 즉 32장은 그대로 유지, 각이미지를 1D 벡터로 펼친것\n",
    "# 배치차원은 아래와 같이 입력층 바로 뒤에 추가\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Input(shape=(28,28)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "# 784개의 입력이 첫 번째 은닉층에 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2987cf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5358 - accuracy: 0.8119\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3936 - accuracy: 0.8579\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3564 - accuracy: 0.8712\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3352 - accuracy: 0.8799\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3180 - accuracy: 0.8864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7a35481de1d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련데이터를 다시 준비 및 훈련\n",
    "(train_input, train_target), (test_input, test_target) =\\\n",
    "    keras.datasets.fashion_mnist.load_data()\n",
    "train_scaled = train_input/255.0\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_scaled, train_target, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4254754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 0s 969us/step - loss: 0.3518 - accuracy: 0.8769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3517874777317047, 0.8769166469573975]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 검증세트에서의 성능 확인\n",
    "model.evaluate(val_scaled, val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94e6a2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저 -> 케라스의 다양한 종류의 경사하강법 알고리즘\n",
    "# 기본 경사하강법 옵티마이저 ->SGD 클래스에서 제공, momentum 매개변수의 기본값은 0\n",
    "# 0보다 큰값으로 지정하면 모멘텀 최적화를 사용(보통 0.9이상을 지정)\n",
    "# SGD 클래스의 nesterov 매개변수를 기본값 False에서 True로 바꾸면 네스테로프 모멘텀 최적화를 사용, ex. sgd = keras.optimizers.SGD(momentum=0.9, nesterov=True)\n",
    "# 네스테로프 모멘텀은 모멘텀 최적화를 2번 반복하여 구현\n",
    "# 모델이 최적점에 가까이 갈수록 학습률을 낮출 수 있다. -> 적응적 학습률\n",
    "# 적응적 학습률을 사용하는 대표적인 optimizer -> Adagrad, RMSprop\n",
    "# 모멘텀 최적화와 RMSprop의 장점을 접목한 것 ->  Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fe45dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "# Adam클래스의 매개변수 기본값을 사용해 모델 훈련\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Input(shape=(28,28)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6183730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5288 - accuracy: 0.8156\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3986 - accuracy: 0.8575\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3572 - accuracy: 0.8708\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3304 - accuracy: 0.8792\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3124 - accuracy: 0.8848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7a360079c700>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile() 메서드의 optimizer를 'adam'으로 설정하고 5번의 에포크 동안 훈련\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_scaled, train_target, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "819fe3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 0s 1ms/step - loss: 0.3371 - accuracy: 0.8803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3371421992778778, 0.8803333044052124]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 검증세트에서 성능 확인\n",
    "model.evaluate(val_scaled, val_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
